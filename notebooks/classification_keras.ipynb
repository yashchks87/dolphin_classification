{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "import sys\n",
    "sys.path.append('../scripts/helper_functions_cv/tensorflow_helpers/')\n",
    "from save_weights_every_epoch import CallbackForSavingModelWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "allowed_gpus = [0]\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "final_gpu_list = [gpus[x] for x in allowed_gpus]\n",
    "tf.config.set_visible_devices(final_gpu_list, \"GPU\")\n",
    "for gpu in final_gpu_list:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = pd.read_csv('../../files/train.csv')\n",
    "csv_file['updated_paths'] = csv_file['image'].apply(lambda x: '../../files/train_images/' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(csv_file, test_size):\n",
    "    train, test = train_test_split(csv_file, test_size=test_size)\n",
    "    train, val = train_test_split(train, test_size=test_size)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_data(csv_data):\n",
    "    labels = csv_data['species'].values.tolist()\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder = encoder.fit(np.array(labels).reshape(-1, 1))\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoding_data(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_datasets(csv_file, test_size = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_imgs(img, label):\n",
    "    img = tf.io.read_file(img)\n",
    "    img = tf.image.decode_jpeg(img, channels = 3)\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.resize(img, (512, 512))\n",
    "    img = img / 255\n",
    "    return img, label\n",
    "\n",
    "def read_imgs(img, label):\n",
    "    img = tf.io.read_file(img)\n",
    "    img = tf.image.decode_jpeg(img, channels = 3)\n",
    "    img = tf.image.resize(img, (512, 512))\n",
    "    img = img / 255\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(csv_file, encoder, is_train = True, repeat = True, batch=True, shuffle=True, batch_size=32):\n",
    "    imgs, labels = csv_file['updated_paths'].values.tolist(), csv_file['species'].values.tolist()\n",
    "    labels = encoder.transform(np.array(labels).reshape(-1, 1)).toarray()\n",
    "    tensor = tf.data.Dataset.from_tensor_slices((imgs, labels))\n",
    "    tensor = tensor.cache()\n",
    "    if repeat:\n",
    "        tensor = tensor.repeat()\n",
    "    if shuffle:\n",
    "        tensor = tensor.shuffle(256 * REPLICAS)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        tensor = tensor.with_options(opt)\n",
    "    if is_train:\n",
    "        tensor = tensor.map(read_train_imgs, num_parallel_calls=AUTO)\n",
    "    else:\n",
    "        tensor = tensor.map(read_imgs, num_parallel_calls=AUTO)\n",
    "    if batch:\n",
    "        tensor = tensor.batch(batch_size * REPLICAS)\n",
    "    tensor = tensor.prefetch(AUTO)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input_layer = keras.layers.Input((512, 512, 3))\n",
    "    model_layer = keras.applications.InceptionV3(\n",
    "        include_top=False,\n",
    "        weights = None,\n",
    "        input_shape=(512, 512, 3),\n",
    "        pooling = 'avg'\n",
    "    )(input_layer)\n",
    "    last_layer = keras.layers.Dense(30, activation='softmax')(model_layer)\n",
    "    model = tf.keras.Model(\n",
    "        input_layer,\n",
    "        last_layer,\n",
    "        name = 'IncepModel'\n",
    "    )\n",
    "    # model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_new_model():\n",
    "    with strategy.scope():\n",
    "        model = get_model()\n",
    "        losses = keras.losses.CategoricalCrossentropy(),\n",
    "        metrics = [\n",
    "            keras.metrics.Precision(name='prec'),\n",
    "            keras.metrics.Recall(name='rec')\n",
    "        ]\n",
    "        model.compile(\n",
    "            optimizer = keras.optimizers.SGD(),\n",
    "            loss = losses,\n",
    "            metrics = metrics\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_data(csv_file, encoder, repeat = True, batch=True, shuffle=True, batch_size=32):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:82w9ba3c) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▃▅▆█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▃▂▁</td></tr><tr><td>epoch/prec</td><td>▁▄▆▇█</td></tr><tr><td>epoch/rec</td><td>▁▄▆▇█</td></tr><tr><td>epoch/val_loss</td><td>█▄▂▁▃</td></tr><tr><td>epoch/val_prec</td><td>▁▇██▆</td></tr><tr><td>epoch/val_rec</td><td>▁▄▇█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>4</td></tr><tr><td>epoch/learning_rate</td><td>0.01</td></tr><tr><td>epoch/loss</td><td>0.72959</td></tr><tr><td>epoch/prec</td><td>0.88624</td></tr><tr><td>epoch/rec</td><td>0.68654</td></tr><tr><td>epoch/val_loss</td><td>1.6817</td></tr><tr><td>epoch/val_prec</td><td>0.62575</td></tr><tr><td>epoch/val_rec</td><td>0.41304</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hardy-blaze-26</strong> at: <a href='https://wandb.ai/yashchks87/dolphin/runs/82w9ba3c' target=\"_blank\">https://wandb.ai/yashchks87/dolphin/runs/82w9ba3c</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230811_171005-82w9ba3c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:82w9ba3c). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/dolphin_classification/notebooks/wandb/run-20230811_172836-yvghlcba</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yashchks87/dolphin/runs/yvghlcba' target=\"_blank\">serene-waterfall-27</a></strong> to <a href='https://wandb.ai/yashchks87/dolphin' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yashchks87/dolphin' target=\"_blank\">https://wandb.ai/yashchks87/dolphin</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yashchks87/dolphin/runs/yvghlcba' target=\"_blank\">https://wandb.ai/yashchks87/dolphin/runs/yvghlcba</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  6/284 [..............................] - ETA: 2:51 - loss: 3.2296 - prec: 0.0000e+00 - rec: 0.0000e+00WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2570s vs `on_train_batch_end` time: 0.3000s). Check your callbacks.\n",
      "284/284 [==============================] - 199s 636ms/step - loss: 1.9848 - prec: 0.7761 - rec: 0.1941 - val_loss: 3.9685 - val_prec: 0.0556 - val_rec: 0.0020\n",
      "Epoch 2/50\n",
      "284/284 [==============================] - 180s 634ms/step - loss: 1.2738 - prec: 0.8332 - rec: 0.4653 - val_loss: 1.6957 - val_prec: 0.7677 - val_rec: 0.3854\n",
      "Epoch 3/50\n",
      "284/284 [==============================] - 180s 634ms/step - loss: 0.9781 - prec: 0.8625 - rec: 0.5820 - val_loss: 1.3917 - val_prec: 0.7515 - val_rec: 0.5079\n",
      "Epoch 4/50\n",
      "284/284 [==============================] - 179s 631ms/step - loss: 0.7978 - prec: 0.8838 - rec: 0.6597 - val_loss: 1.4626 - val_prec: 0.7316 - val_rec: 0.4526\n",
      "Epoch 5/50\n",
      "284/284 [==============================] - 180s 633ms/step - loss: 0.6620 - prec: 0.8961 - rec: 0.7169 - val_loss: 0.9016 - val_prec: 0.8260 - val_rec: 0.6660\n",
      "Epoch 6/50\n",
      "284/284 [==============================] - 180s 634ms/step - loss: 0.5570 - prec: 0.9110 - rec: 0.7638 - val_loss: 0.9599 - val_prec: 0.7976 - val_rec: 0.6462\n",
      "Epoch 7/50\n",
      "284/284 [==============================] - 180s 634ms/step - loss: 0.4746 - prec: 0.9229 - rec: 0.8008 - val_loss: 0.8825 - val_prec: 0.8058 - val_rec: 0.6640\n",
      "Epoch 8/50\n",
      "284/284 [==============================] - 180s 634ms/step - loss: 0.4067 - prec: 0.9321 - rec: 0.8315 - val_loss: 0.8737 - val_prec: 0.8186 - val_rec: 0.6779\n",
      "Epoch 9/50\n",
      "284/284 [==============================] - 179s 630ms/step - loss: 0.3531 - prec: 0.9388 - rec: 0.8525 - val_loss: 1.0647 - val_prec: 0.7825 - val_rec: 0.6542\n",
      "Epoch 10/50\n",
      "284/284 [==============================] - 179s 631ms/step - loss: 0.3030 - prec: 0.9476 - rec: 0.8747 - val_loss: 1.7731 - val_prec: 0.7438 - val_rec: 0.6482\n",
      "Epoch 11/50\n",
      "284/284 [==============================] - 180s 634ms/step - loss: 0.2642 - prec: 0.9540 - rec: 0.8914 - val_loss: 0.7831 - val_prec: 0.8427 - val_rec: 0.7095\n",
      "Epoch 12/50\n",
      "284/284 [==============================] - 179s 631ms/step - loss: 0.2341 - prec: 0.9585 - rec: 0.9035 - val_loss: 0.6694 - val_prec: 0.8622 - val_rec: 0.7668\n",
      "Epoch 13/50\n",
      "284/284 [==============================] - 179s 629ms/step - loss: 0.2012 - prec: 0.9666 - rec: 0.9177 - val_loss: 0.6085 - val_prec: 0.8654 - val_rec: 0.8004\n",
      "Epoch 14/50\n",
      "284/284 [==============================] - 179s 630ms/step - loss: 0.1752 - prec: 0.9697 - rec: 0.9283 - val_loss: 0.6916 - val_prec: 0.8534 - val_rec: 0.7708\n",
      "Epoch 15/50\n",
      "284/284 [==============================] - 179s 632ms/step - loss: 0.1454 - prec: 0.9765 - rec: 0.9410 - val_loss: 1.0148 - val_prec: 0.8150 - val_rec: 0.7312\n",
      "Epoch 16/50\n",
      "284/284 [==============================] - 179s 630ms/step - loss: 0.1343 - prec: 0.9771 - rec: 0.9454 - val_loss: 0.7369 - val_prec: 0.8319 - val_rec: 0.7727\n",
      "Epoch 17/50\n",
      "284/284 [==============================] - 179s 632ms/step - loss: 0.1113 - prec: 0.9822 - rec: 0.9559 - val_loss: 0.4032 - val_prec: 0.9027 - val_rec: 0.8617\n",
      "Epoch 18/50\n",
      "284/284 [==============================] - 180s 634ms/step - loss: 0.0999 - prec: 0.9844 - rec: 0.9622 - val_loss: 0.5889 - val_prec: 0.8787 - val_rec: 0.8162\n",
      "Epoch 19/50\n",
      "284/284 [==============================] - 179s 630ms/step - loss: 0.0896 - prec: 0.9856 - rec: 0.9652 - val_loss: 0.3480 - val_prec: 0.9198 - val_rec: 0.8834\n",
      "Epoch 20/50\n",
      "284/284 [==============================] - 180s 635ms/step - loss: 0.0690 - prec: 0.9900 - rec: 0.9746 - val_loss: 0.3331 - val_prec: 0.9089 - val_rec: 0.8874\n",
      "Epoch 21/50\n",
      "284/284 [==============================] - 180s 633ms/step - loss: 0.0629 - prec: 0.9907 - rec: 0.9771 - val_loss: 0.5184 - val_prec: 0.8912 - val_rec: 0.8577\n",
      "Epoch 22/50\n",
      "284/284 [==============================] - 179s 630ms/step - loss: 0.0555 - prec: 0.9922 - rec: 0.9803 - val_loss: 0.4338 - val_prec: 0.9130 - val_rec: 0.8715\n",
      "Epoch 23/50\n",
      "284/284 [==============================] - 180s 634ms/step - loss: 0.0543 - prec: 0.9918 - rec: 0.9811 - val_loss: 0.4253 - val_prec: 0.8998 - val_rec: 0.8696\n",
      "Epoch 24/50\n",
      "284/284 [==============================] - 179s 630ms/step - loss: 0.0442 - prec: 0.9939 - rec: 0.9849 - val_loss: 0.4740 - val_prec: 0.8837 - val_rec: 0.8557\n",
      "Epoch 25/50\n",
      "284/284 [==============================] - 179s 631ms/step - loss: 0.0425 - prec: 0.9939 - rec: 0.9865 - val_loss: 0.3479 - val_prec: 0.9202 - val_rec: 0.8893\n",
      "Epoch 26/50\n",
      "284/284 [==============================] - 179s 630ms/step - loss: 0.0399 - prec: 0.9941 - rec: 0.9869 - val_loss: 0.6002 - val_prec: 0.8799 - val_rec: 0.8399\n",
      "Epoch 27/50\n",
      "284/284 [==============================] - 179s 632ms/step - loss: 0.0347 - prec: 0.9949 - rec: 0.9889 - val_loss: 0.3582 - val_prec: 0.9167 - val_rec: 0.8913\n",
      "Epoch 28/50\n",
      "284/284 [==============================] - 179s 631ms/step - loss: 0.0259 - prec: 0.9968 - rec: 0.9926 - val_loss: 0.3727 - val_prec: 0.9322 - val_rec: 0.8972\n",
      "Epoch 29/50\n",
      "284/284 [==============================] - 180s 633ms/step - loss: 0.0221 - prec: 0.9977 - rec: 0.9945 - val_loss: 0.3190 - val_prec: 0.9256 - val_rec: 0.9091\n",
      "Epoch 30/50\n",
      "284/284 [==============================] - 180s 633ms/step - loss: 0.0179 - prec: 0.9983 - rec: 0.9958 - val_loss: 0.3664 - val_prec: 0.9228 - val_rec: 0.8972\n",
      "Epoch 31/50\n",
      "284/284 [==============================] - 179s 630ms/step - loss: 0.0194 - prec: 0.9977 - rec: 0.9952 - val_loss: 0.3574 - val_prec: 0.9268 - val_rec: 0.9012\n",
      "Epoch 32/50\n",
      "284/284 [==============================] - 180s 633ms/step - loss: 0.0163 - prec: 0.9984 - rec: 0.9964 - val_loss: 0.3715 - val_prec: 0.9268 - val_rec: 0.9012\n",
      "Epoch 33/50\n",
      "284/284 [==============================] - 180s 633ms/step - loss: 0.0151 - prec: 0.9984 - rec: 0.9963 - val_loss: 0.3810 - val_prec: 0.9231 - val_rec: 0.9012\n",
      "Epoch 34/50\n",
      "284/284 [==============================] - 179s 630ms/step - loss: 0.0171 - prec: 0.9980 - rec: 0.9961 - val_loss: 0.5252 - val_prec: 0.8889 - val_rec: 0.8538\n",
      "Epoch 35/50\n",
      "284/284 [==============================] - 179s 630ms/step - loss: 0.0146 - prec: 0.9984 - rec: 0.9968 - val_loss: 0.3448 - val_prec: 0.9215 - val_rec: 0.9051\n",
      "Epoch 36/50\n",
      "284/284 [==============================] - 180s 633ms/step - loss: 0.0137 - prec: 0.9984 - rec: 0.9971 - val_loss: 0.3733 - val_prec: 0.9194 - val_rec: 0.9012\n",
      "Epoch 37/50\n",
      "284/284 [==============================] - 180s 635ms/step - loss: 0.0091 - prec: 0.9994 - rec: 0.9984 - val_loss: 0.3100 - val_prec: 0.9357 - val_rec: 0.9209\n",
      "Epoch 38/50\n",
      "284/284 [==============================] - 180s 635ms/step - loss: 0.0080 - prec: 0.9995 - rec: 0.9988 - val_loss: 0.4528 - val_prec: 0.9051 - val_rec: 0.8854\n",
      "Epoch 39/50\n",
      "284/284 [==============================] - 180s 634ms/step - loss: 0.0104 - prec: 0.9989 - rec: 0.9980 - val_loss: 0.9287 - val_prec: 0.8143 - val_rec: 0.7628\n",
      "Epoch 40/50\n",
      "140/284 [=============>................] - ETA: 1:30 - loss: 0.0077 - prec: 0.9995 - rec: 0.9988"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-077c09374b71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_new_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m hist = model.fit(\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1654\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             raise ValueError(\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_batch_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs, is_batch_hook)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_batch_hook\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_hooks_support_tf_logs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \"\"\"\n\u001b[1;32m   1154\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1156\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path_to_save = '../../tf_weights/incep_v1/'\n",
    "save_weights = CallbackForSavingModelWeights(path_to_save)\n",
    "batch_size = 176\n",
    "train_dataset = get_data(train, encoder, batch_size = batch_size)\n",
    "val_dataset = get_data(val, encoder, shuffle = False, repeat = False, batch_size = batch_size)\n",
    "wandb.init(\n",
    "    project='dolphin',\n",
    "    config = {\n",
    "        'batch_size' : batch_size,\n",
    "    }\n",
    ")\n",
    "model = compile_new_model()\n",
    "hist = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data = val_dataset,\n",
    "    steps_per_epoch = len(train) // batch_size,\n",
    "    epochs = 50,\n",
    "    verbose = 1,\n",
    "    callbacks = [\n",
    "        WandbMetricsLogger(),\n",
    "        save_weights\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myashchks87\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/dolphin_classification/notebooks/wandb/run-20230811_193116-bsx24qij</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yashchks87/dolphin/runs/bsx24qij' target=\"_blank\">stilted-night-28</a></strong> to <a href='https://wandb.ai/yashchks87/dolphin' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yashchks87/dolphin' target=\"_blank\">https://wandb.ai/yashchks87/dolphin</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yashchks87/dolphin/runs/bsx24qij' target=\"_blank\">https://wandb.ai/yashchks87/dolphin/runs/bsx24qij</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/50\n",
      "  6/284 [..............................] - ETA: 2:52 - loss: 3.2140 - prec: 0.0000e+00 - rec: 0.0000e+00WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2483s vs `on_train_batch_end` time: 0.3087s). Check your callbacks.\n",
      "284/284 [==============================] - 218s 643ms/step - loss: 1.9765 - prec: 0.7748 - rec: 0.1909 - val_loss: 4.0688 - val_prec: 0.3500 - val_rec: 0.0138\n",
      "Epoch 2/50\n",
      "284/284 [==============================] - 179s 631ms/step - loss: 1.2537 - prec: 0.8326 - rec: 0.4712 - val_loss: 2.6427 - val_prec: 0.4249 - val_rec: 0.2964\n",
      "Epoch 3/50\n",
      "284/284 [==============================] - 180s 635ms/step - loss: 0.9654 - prec: 0.8627 - rec: 0.5873 - val_loss: 1.1488 - val_prec: 0.7432 - val_rec: 0.5375\n",
      "Epoch 4/50\n",
      "284/284 [==============================] - 180s 634ms/step - loss: 0.7854 - prec: 0.8828 - rec: 0.6643 - val_loss: 0.8049 - val_prec: 0.8901 - val_rec: 0.6561\n",
      "Epoch 5/50\n",
      "284/284 [==============================] - 179s 631ms/step - loss: 0.6564 - prec: 0.8962 - rec: 0.7206 - val_loss: 1.0992 - val_prec: 0.7669 - val_rec: 0.6047\n",
      "Epoch 6/50\n",
      "284/284 [==============================] - 180s 633ms/step - loss: 0.5585 - prec: 0.9073 - rec: 0.7654 - val_loss: 0.8238 - val_prec: 0.8556 - val_rec: 0.6443\n",
      "Epoch 7/50\n",
      "284/284 [==============================] - 180s 633ms/step - loss: 0.4814 - prec: 0.9187 - rec: 0.7994 - val_loss: 0.7477 - val_prec: 0.8456 - val_rec: 0.7036\n",
      "Epoch 8/50\n",
      "284/284 [==============================] - 179s 629ms/step - loss: 0.4184 - prec: 0.9277 - rec: 0.8261 - val_loss: 0.6949 - val_prec: 0.8490 - val_rec: 0.7332\n",
      "Epoch 9/50\n",
      "284/284 [==============================] - 179s 631ms/step - loss: 0.3708 - prec: 0.9334 - rec: 0.8465 - val_loss: 0.6412 - val_prec: 0.8659 - val_rec: 0.7273\n",
      "Epoch 10/50\n",
      "284/284 [==============================] - 179s 630ms/step - loss: 0.3297 - prec: 0.9397 - rec: 0.8639 - val_loss: 0.4439 - val_prec: 0.9089 - val_rec: 0.8281\n",
      "Epoch 11/50\n",
      "284/284 [==============================] - 179s 630ms/step - loss: 0.2942 - prec: 0.9476 - rec: 0.8787 - val_loss: 0.5624 - val_prec: 0.8736 - val_rec: 0.7925\n",
      "Epoch 12/50\n",
      "284/284 [==============================] - 180s 633ms/step - loss: 0.2644 - prec: 0.9512 - rec: 0.8919 - val_loss: 0.7136 - val_prec: 0.8448 - val_rec: 0.7530\n",
      "Epoch 13/50\n",
      "284/284 [==============================] - 180s 635ms/step - loss: 0.2374 - prec: 0.9556 - rec: 0.9021 - val_loss: 0.3990 - val_prec: 0.9074 - val_rec: 0.8518\n",
      "Epoch 14/50\n",
      "284/284 [==============================] - 179s 630ms/step - loss: 0.2132 - prec: 0.9591 - rec: 0.9133 - val_loss: 0.5058 - val_prec: 0.8913 - val_rec: 0.8103\n",
      "Epoch 15/50\n",
      "284/284 [==============================] - 180s 634ms/step - loss: 0.1950 - prec: 0.9636 - rec: 0.9217 - val_loss: 0.6093 - val_prec: 0.8661 - val_rec: 0.7925\n",
      "Epoch 16/50\n",
      "284/284 [==============================] - 180s 634ms/step - loss: 0.1755 - prec: 0.9677 - rec: 0.9297 - val_loss: 0.4178 - val_prec: 0.9188 - val_rec: 0.8498\n",
      "Epoch 17/50\n",
      "284/284 [==============================] - 180s 634ms/step - loss: 0.1559 - prec: 0.9714 - rec: 0.9385 - val_loss: 0.5551 - val_prec: 0.8821 - val_rec: 0.7984\n",
      "Epoch 18/50\n",
      "284/284 [==============================] - 179s 629ms/step - loss: 0.1420 - prec: 0.9738 - rec: 0.9431 - val_loss: 0.4693 - val_prec: 0.8898 - val_rec: 0.8142\n",
      "Epoch 19/50\n",
      "284/284 [==============================] - 180s 633ms/step - loss: 0.1301 - prec: 0.9755 - rec: 0.9476 - val_loss: 0.3067 - val_prec: 0.9203 - val_rec: 0.8676\n",
      "Epoch 20/50\n",
      "284/284 [==============================] - 179s 631ms/step - loss: 0.1193 - prec: 0.9775 - rec: 0.9525 - val_loss: 0.2979 - val_prec: 0.9366 - val_rec: 0.8755\n",
      "Epoch 21/50\n",
      "284/284 [==============================] - 179s 630ms/step - loss: 0.1052 - prec: 0.9803 - rec: 0.9585 - val_loss: 0.4038 - val_prec: 0.9036 - val_rec: 0.8518\n",
      "Epoch 22/50\n",
      "284/284 [==============================] - 179s 630ms/step - loss: 0.0957 - prec: 0.9830 - rec: 0.9623 - val_loss: 0.3167 - val_prec: 0.9205 - val_rec: 0.8696\n",
      "Epoch 23/50\n",
      "284/284 [==============================] - 179s 631ms/step - loss: 0.0845 - prec: 0.9853 - rec: 0.9668 - val_loss: 0.3672 - val_prec: 0.9349 - val_rec: 0.8794\n",
      "Epoch 24/50\n",
      "284/284 [==============================] - 180s 633ms/step - loss: 0.0820 - prec: 0.9846 - rec: 0.9686 - val_loss: 0.2580 - val_prec: 0.9305 - val_rec: 0.8992\n",
      "Epoch 25/50\n",
      "284/284 [==============================] - 179s 630ms/step - loss: 0.0722 - prec: 0.9863 - rec: 0.9721 - val_loss: 0.3011 - val_prec: 0.9268 - val_rec: 0.9012\n",
      "Epoch 26/50\n",
      "284/284 [==============================] - 179s 630ms/step - loss: 0.0651 - prec: 0.9881 - rec: 0.9756 - val_loss: 0.2870 - val_prec: 0.9299 - val_rec: 0.8913\n",
      "Epoch 27/50\n",
      "284/284 [==============================] - 179s 632ms/step - loss: 0.0581 - prec: 0.9901 - rec: 0.9784 - val_loss: 0.2750 - val_prec: 0.9289 - val_rec: 0.9032\n",
      "Epoch 28/50\n",
      "284/284 [==============================] - 180s 634ms/step - loss: 0.0549 - prec: 0.9908 - rec: 0.9802 - val_loss: 0.3093 - val_prec: 0.9185 - val_rec: 0.8913\n",
      "Epoch 29/50\n",
      "284/284 [==============================] - 181s 637ms/step - loss: 0.0502 - prec: 0.9911 - rec: 0.9822 - val_loss: 0.2857 - val_prec: 0.9316 - val_rec: 0.9150\n",
      "Epoch 30/50\n",
      "284/284 [==============================] - 180s 635ms/step - loss: 0.0456 - prec: 0.9921 - rec: 0.9838 - val_loss: 0.2988 - val_prec: 0.9286 - val_rec: 0.8992\n",
      "Epoch 31/50\n",
      "284/284 [==============================] - 179s 631ms/step - loss: 0.0457 - prec: 0.9916 - rec: 0.9838 - val_loss: 0.3091 - val_prec: 0.9346 - val_rec: 0.9032\n",
      "Epoch 32/50\n",
      "284/284 [==============================] - 179s 631ms/step - loss: 0.0359 - prec: 0.9939 - rec: 0.9874 - val_loss: 0.2638 - val_prec: 0.9262 - val_rec: 0.8933\n",
      "Epoch 33/50\n",
      "284/284 [==============================] - 180s 635ms/step - loss: 0.0349 - prec: 0.9944 - rec: 0.9884 - val_loss: 0.2085 - val_prec: 0.9476 - val_rec: 0.9289\n",
      "Epoch 34/50\n",
      "284/284 [==============================] - 179s 632ms/step - loss: 0.0327 - prec: 0.9943 - rec: 0.9889 - val_loss: 0.2851 - val_prec: 0.9276 - val_rec: 0.9111\n",
      "Epoch 35/50\n",
      "284/284 [==============================] - 180s 635ms/step - loss: 0.0307 - prec: 0.9948 - rec: 0.9900 - val_loss: 0.2387 - val_prec: 0.9393 - val_rec: 0.9170\n",
      "Epoch 36/50\n",
      "284/284 [==============================] - 180s 633ms/step - loss: 0.0313 - prec: 0.9944 - rec: 0.9898 - val_loss: 0.2912 - val_prec: 0.9259 - val_rec: 0.9130\n",
      "Epoch 37/50\n",
      "284/284 [==============================] - 181s 638ms/step - loss: 0.0272 - prec: 0.9954 - rec: 0.9915 - val_loss: 0.2344 - val_prec: 0.9469 - val_rec: 0.9170\n",
      "Epoch 38/50\n",
      "284/284 [==============================] - 180s 633ms/step - loss: 0.0254 - prec: 0.9961 - rec: 0.9925 - val_loss: 0.2350 - val_prec: 0.9294 - val_rec: 0.9111\n",
      "Epoch 39/50\n",
      "284/284 [==============================] - 180s 632ms/step - loss: 0.0270 - prec: 0.9946 - rec: 0.9910 - val_loss: 0.2423 - val_prec: 0.9319 - val_rec: 0.9190\n",
      "Epoch 40/50\n",
      "284/284 [==============================] - 180s 633ms/step - loss: 0.0223 - prec: 0.9964 - rec: 0.9933 - val_loss: 0.3284 - val_prec: 0.9108 - val_rec: 0.8874\n",
      "Epoch 41/50\n",
      "284/284 [==============================] - 180s 636ms/step - loss: 0.0233 - prec: 0.9957 - rec: 0.9926 - val_loss: 0.1529 - val_prec: 0.9577 - val_rec: 0.9387\n",
      "Epoch 42/50\n",
      "284/284 [==============================] - 180s 634ms/step - loss: 0.0176 - prec: 0.9975 - rec: 0.9953 - val_loss: 0.1698 - val_prec: 0.9557 - val_rec: 0.9387\n",
      "Epoch 43/50\n",
      "284/284 [==============================] - 179s 632ms/step - loss: 0.0180 - prec: 0.9971 - rec: 0.9948 - val_loss: 0.1971 - val_prec: 0.9515 - val_rec: 0.9308\n",
      "Epoch 44/50\n",
      "284/284 [==============================] - 181s 638ms/step - loss: 0.0173 - prec: 0.9972 - rec: 0.9950 - val_loss: 0.1945 - val_prec: 0.9519 - val_rec: 0.9387\n",
      "Epoch 45/50\n",
      "284/284 [==============================] - 180s 633ms/step - loss: 0.0164 - prec: 0.9972 - rec: 0.9954 - val_loss: 0.2872 - val_prec: 0.9279 - val_rec: 0.9150\n",
      "Epoch 46/50\n",
      "284/284 [==============================] - 180s 634ms/step - loss: 0.0147 - prec: 0.9979 - rec: 0.9962 - val_loss: 0.1732 - val_prec: 0.9522 - val_rec: 0.9447\n",
      "Epoch 47/50\n",
      "284/284 [==============================] - 181s 637ms/step - loss: 0.0155 - prec: 0.9976 - rec: 0.9959 - val_loss: 0.2386 - val_prec: 0.9453 - val_rec: 0.9229\n",
      "Epoch 48/50\n",
      "284/284 [==============================] - 179s 632ms/step - loss: 0.0143 - prec: 0.9976 - rec: 0.9961 - val_loss: 0.2283 - val_prec: 0.9496 - val_rec: 0.9308\n",
      "Epoch 49/50\n",
      "284/284 [==============================] - 179s 631ms/step - loss: 0.0105 - prec: 0.9988 - rec: 0.9979 - val_loss: 0.2579 - val_prec: 0.9359 - val_rec: 0.9229\n",
      "Epoch 50/50\n",
      "284/284 [==============================] - 179s 631ms/step - loss: 0.0090 - prec: 0.9991 - rec: 0.9981 - val_loss: 0.1855 - val_prec: 0.9498 - val_rec: 0.9348\n"
     ]
    }
   ],
   "source": [
    "path_to_save = '../../tf_weights/incep_v1_flip_iamges/'\n",
    "save_weights = CallbackForSavingModelWeights(path_to_save)\n",
    "batch_size = 176\n",
    "train_dataset = get_data(train, encoder, is_train = True, batch_size = batch_size)\n",
    "val_dataset = get_data(val, encoder, is_train = False, shuffle = False, repeat = False, batch_size = batch_size)\n",
    "wandb.init(\n",
    "    project='dolphin',\n",
    "    config = {\n",
    "        'batch_size' : batch_size,\n",
    "        'flip_left_right' : True,\n",
    "    }\n",
    ")\n",
    "model = compile_new_model()\n",
    "hist = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data = val_dataset,\n",
    "    steps_per_epoch = len(train) // batch_size,\n",
    "    epochs = 50,\n",
    "    verbose = 1,\n",
    "    callbacks = [\n",
    "        WandbMetricsLogger(),\n",
    "        save_weights\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "base_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
